{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFHUMknn7CqujrJCfj0XDL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SapnaNauhriaMicrosoft/skills-code-with-codespaces/blob/main/DLAssignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports (RUN ME!) { display-mode: \"form\" }\n",
        "\n",
        "!pip install tensorflow-gpu==2.0.0-beta0 > /dev/null 2>&1\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"TensorFlow executing eagerly: {}\".format(tf.executing_eagerly()))"
      ],
      "metadata": {
        "id": "YhwP4h4Lpuyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The Data"
      ],
      "metadata": {
        "id": "Qvhg96h_pokY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow has convenient modules for loading a number of standard datasets\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_and_validation_images, train_and_validation_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "text_labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "metadata": {
        "id": "KcRMkVUUp9OV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construct a validation set"
      ],
      "metadata": {
        "id": "sdGWm8COqP3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct a validation set from the last 10000 images and labels from\n",
        "# train_and_validation_images and train_and_validation_labels\n",
        "validation_images = train_and_validation_images[-10000:, :, :]\n",
        "validation_labels = train_and_validation_labels[-10000:]\n",
        "\n",
        "# Construct a training set from the first 50000 images and labels.\n",
        "train_images = train_and_validation_images[:50000, :, :]\n",
        "train_labels = train_and_validation_labels[:50000]"
      ],
      "metadata": {
        "id": "Wsg19Gs_qRfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization"
      ],
      "metadata": {
        "id": "__GWAmfXqZZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We use the Matplotlib plotting library to visualise an image selected at random from the training set\n",
        "plt.figure()\n",
        "random_index = np.random.randint(0, len(train_images))\n",
        "plt.imshow(train_images[random_index], cmap='gray_r')\n",
        "plt.colorbar()\n",
        "numerical_label = train_labels[random_index]\n",
        "text_description = text_labels[numerical_label]\n",
        "plt.title('True Class: {} (\"{}\")'.format(numerical_label, text_description))\n",
        "\n",
        "plt.gca().grid(False)\n",
        "\n",
        "# Another view, showing 25 randomly selected images at a time\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "\n",
        "    img_index = np.random.randint(0, 50000)\n",
        "    plt.imshow(train_images[img_index], cmap=\"gray_r\")\n",
        "    plt.xlabel(text_labels[train_labels[img_index]])"
      ],
      "metadata": {
        "id": "Q6R0MnTCqc2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the data with TensorFlow"
      ],
      "metadata": {
        "id": "23yjcaZEq2IM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n"
      ],
      "metadata": {
        "id": "imAqi_cPq3d1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))"
      ],
      "metadata": {
        "id": "foOgssEOq81m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide image values and cast to float so that they end up as a floating point number between 0 and 1\n",
        "train_ds = train_ds.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, tf.cast(y, tf.int32)))"
      ],
      "metadata": {
        "id": "Vk3wmUASrDij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the examples.\n",
        "train_ds = train_ds.shuffle(buffer_size=batch_size * 10)"
      ],
      "metadata": {
        "id": "5RYayDzjrF-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now \"chunk\" the examples into batches\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "\n",
        "# The output of this pipeline will be tuples of tensors containing images and labels.\n",
        "# The images will be of shape (batch_size, 28, 28) and the labels of shape (batch_size, )"
      ],
      "metadata": {
        "id": "XgG8ouW0rIWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Don't worry about this for now, we will use the validation set later\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))\n",
        "val_ds = val_ds.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, tf.cast(y, tf.int32)))\n",
        "val_ds = val_ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "2hDbIGr3rLUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure the feed-forward neural network"
      ],
      "metadata": {
        "id": "7d62ky0LrQ76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RE-RUN THIS CELL if you want to restart training!\n",
        "model = tf.keras.Sequential([\n",
        "    # Convert the 28x28 image into a flat vector of 28x28 = 784 values\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28), name='flatten_input'),\n",
        "    # Create a \"hidden\" layer with 256 neurons and apply the ReLU non-linearity\n",
        "    tf.keras.layers.Dense(256, activation=tf.nn.relu, name='input_to_hidden1'),\n",
        "    # Create another hidden layer with 128 neurons\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu, name='hidden1_to_hidden2'),\n",
        "    # Create an \"output layer\" with 10 neurons\n",
        "    tf.keras.layers.Dense(10, name='hidden_to_logits'),\n",
        "])"
      ],
      "metadata": {
        "id": "ZfPBPI4MrSg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "PnHTio6Srk3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model\n",
        "Defining Training Loop"
      ],
      "metadata": {
        "id": "bcAA5Zdvrq42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose an optimizer and loss function for training:\n",
        "# The optimizer is responsible for controlling the learning rate\n",
        "optimizer = tf.keras.optimizers.Adam()  # Set explicitly for reproducibility\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Select metrics to measure the loss and the accuracy of the model.\n",
        "# These metrics accumulate the values over epochs and then print the overall result.\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "num_epochs = 50  # The number of epochs to run\n",
        "\n",
        "# Lists to store the loss and accuracy of every epoch\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "\n",
        "# Defined a function to train the model using tf.GradientTape\n",
        "@tf.function\n",
        "def train_step(image, label):\n",
        "  # Initialise a GradientTape to track the operations\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Compute the logits (un-normalised scores) of the current batch of examples\n",
        "    # using the neural network architecture we defined earlier\n",
        "    logits = model(image)\n",
        "    loss = loss_object(label, logits)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  # Add current batch loss to our loss metric tracker - note the function call semantics\n",
        "  train_loss(loss)\n",
        "  train_accuracy(label, logits)\n",
        "\n",
        "# Define a function to test the model\n",
        "# @tf.function\n",
        "# def val_step(image, label):\n",
        "  # TODO\n",
        "\n",
        "def val_step(image, label):\n",
        "  logits = model(image, training=False)      # disable dropout/batchnorm updates\n",
        "  v_loss = loss_object(label, logits)\n",
        "  val_loss(v_loss)\n",
        "  val_accuracy(label, logits)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  # Loop over our data pipeline\n",
        "  for image, label in train_ds:\n",
        "    train_step(image, label)\n",
        "\n",
        "  template = 'Epoch {:03d}, Loss: {:.3f}, Accuracy: {:.3%}'\n",
        "  print(template.format(epoch+1,\n",
        "                        train_loss.result(),\n",
        "                        train_accuracy.result()))\n",
        "\n",
        "  train_losses.append(train_loss.result())\n",
        "  train_accuracies.append(train_accuracy.result())"
      ],
      "metadata": {
        "id": "sm7cHhc4Fz2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the training loop"
      ],
      "metadata": {
        "id": "v_08mlkHsIMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(range(num_epochs), train_losses)\n",
        "plt.title('Loss vs epochs')\n",
        "\n",
        "# Plot the accuracy for all epochs using Matplotlib\n",
        "plt.figure()\n",
        "plt.plot(range(num_epochs), train_accuracies)\n",
        "plt.title('Accuracy vs epochs')"
      ],
      "metadata": {
        "id": "q9aBsk3csK0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualise some of the model's prediction on the training set"
      ],
      "metadata": {
        "id": "qFGAQeIvsWpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(train_ds))  # Get a batch of images and labels\n",
        "\n",
        "_logits = model(images, training=False)  # Pass the images to the model function and get its output logits\n",
        "predicted_labels = tf.argmax(_logits, axis=1, output_type=tf.int32)\n",
        "\n",
        "img_indexs = np.arange(images.numpy().shape[0])\n",
        "np.random.shuffle(img_indexs)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "\n",
        "    img_index = img_indexs[i]\n",
        "    predicted_label = int(predicted_labels[img_index])\n",
        "\n",
        "    plt.imshow(images[img_index], cmap=\"gray_r\")\n",
        "\n",
        "    actual_label = int(labels[img_index].numpy())\n",
        "    plt.xlabel(\"Actual: {} ({})\\n Predicted: {} ({})\".format(\n",
        "        actual_label, text_labels[actual_label], predicted_label, text_labels[predicted_label]\n",
        "    ))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YgtTJVAdsY-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "gs2If3Xqsfrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to apply the same pre-processing to the test set as we did to the training set\n",
        "# Since we don't need batching or shuffling, we can do this directly instead of\n",
        "# building a tf.Dataset pipeline\n",
        "\n",
        "tf_test_images = tf.convert_to_tensor(test_images, dtype=tf.float32) / 255.0\n",
        "tf_test_labels = tf.convert_to_tensor(test_labels, dtype=tf.int32)"
      ],
      "metadata": {
        "id": "SqszZVRWsn_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_logits = model(tf_test_images, training=False)\n",
        "\n",
        "# Compute the average cross-entropy loss of the classification over the entire test set\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "t_loss = loss_object(tf_test_labels, test_logits)\n",
        "test_loss(t_loss)\n",
        "\n",
        "# Compare predicted labels to actual labels\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
        "test_accuracy(tf_test_labels, test_logits)\n",
        "\n",
        "print('Completed testing on', tf_test_images.shape[0], 'examples...')\n",
        "print('Loss: {:.3f}, Accuracy: {:.3%}'.format(test_loss.result(), test_accuracy.result()))"
      ],
      "metadata": {
        "id": "xs67V-uWsud-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visulaizing test data"
      ],
      "metadata": {
        "id": "Cf2ESnRNszj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = tf.argmax(test_logits, axis=1, output_type=tf.int32)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "\n",
        "    img_index = np.random.randint(0, 10000)\n",
        "    plt.imshow(test_images[img_index], cmap=\"gray_r\")\n",
        "\n",
        "    actual_label = int(test_labels[img_index])\n",
        "    predicted_label = int(test_predictions[img_index])\n",
        "\n",
        "    plt.xlabel(\"Actual: {} ({})\\n Predicted: {} ({})\".format(\n",
        "        actual_label, text_labels[actual_label], predicted_label, text_labels[predicted_label]\n",
        "    ))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0DDF08_qs2nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WhwFMYCvuwgu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}